{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_calendar = pd.read_csv(\"Calendar_with_cycled_days.csv\", index_col = 0)\n",
    "date_converter = dict(zip(store_calendar['d'], store_calendar.index))\n",
    "\n",
    "sell_prices = pd.read_csv(\"sell_prices_afcs2021.csv\", index_col=0)\n",
    "\n",
    "sample_submission = pd.read_csv(\"sample_submission_afcs2021.csv\", index_col=0)\n",
    "\n",
    "train_data = pd.read_csv(\"sales_train_validation_afcs2021.csv\", index_col=0)\n",
    "test_data = pd.read_csv(\"sales_test_validation_afcs2021.csv\", index_col=0)\n",
    "train_data = train_data.rename(columns=date_converter)\n",
    "test_data = test_data.rename(columns=date_converter)\n",
    "\n",
    "total_sales = train_data.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt at forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data for calculating the RMSE\n",
    "ts_test_data = test_data.transpose()\n",
    "ts_test_data.index = pd.to_datetime(ts_test_data.index)\n",
    "products = list(ts_test_data.columns.values)\n",
    "\n",
    "for i in products:\n",
    "    p_name = \"_\".join(i.split(\"_\")[:3])\n",
    "    ts_test_data = ts_test_data.rename(columns = {i : p_name})\n",
    "ts_test_data.index.name = 'date'\n",
    "# ts_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the train data\n",
    "ts_train_data = train_data.transpose()\n",
    "ts_train_data.index = pd.to_datetime(ts_train_data.index)\n",
    "products = list(ts_train_data.columns.values)\n",
    "originals = list(ts_train_data.columns.values)\n",
    "\n",
    "for i in products:\n",
    "    p_name = \"_\".join(i.split(\"_\")[:3])\n",
    "    ts_train_data = ts_train_data.rename(columns = {i : p_name})\n",
    "\n",
    "ts_train_data.index.name = 'date'\n",
    "# ts_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for merging\n",
    "store_calendar = store_calendar.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the calendar and sell_price dataframes\n",
    "new = pd.merge(sell_prices, store_calendar, on='wm_yr_wk')\n",
    "new = new.set_index('date')\n",
    "new.index = pd.to_datetime(new.index)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to the sell price so it can be added to the VAR model (variables can't be constant)\n",
    "original = new['sell_price']\n",
    "noise = np.random.normal(0, .01, len(new))\n",
    "new_signal = original + noise\n",
    "new['sell_price'] = new['sell_price'] + noise\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the forecasts\n",
    "def make_forecast(train_data, price, product_names, original_product_names):\n",
    "    submission = []\n",
    "    \n",
    "    for i in range(len(product_names)):\n",
    "        df_train = train_data[product_names[i]]\n",
    "        df_sales = price[price['item_id'] == product_names[i]]\n",
    "        df = pd.merge(df_sales, df_train, on=\"date\")[[product_names[i], 'sin_wday', 'cos_wday', 'sell_price']]\n",
    "        \n",
    "#         The old Holt_Winters model:\n",
    "#         model = ExponentialSmoothing(df ,seasonal_periods=7 ,trend='add', seasonal='add') \n",
    "#         fitted = model.fit() \n",
    "#         fc = fitted.forecast(28).tolist()\n",
    "\n",
    "        model = VAR(endog=df)\n",
    "        model_fit = model.fit()\n",
    "        prediction = model_fit.forecast(model_fit.y, steps=28)\n",
    "\n",
    "        fc = prediction[:,0].tolist()\n",
    "        fc.insert(0, originals[i])\n",
    "        submission.append(fc)\n",
    "\n",
    "    return submission\n",
    " \n",
    "products = list(ts_train_data.columns.values)\n",
    "df = make_forecast(ts_train_data, new, products, originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert forecasts to a dataframe\n",
    "df = pd.DataFrame(df, columns=['id','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17','F18','F19','F20','F21','F22','F23','F24','F25','F26','F27','F28'])\n",
    "df = df.set_index('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSE\n",
    "np.sqrt(mean_squared_error(df, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best RMSE for comparison\n",
    "best = df\n",
    "np.sqrt(mean_squared_error(best, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CSV file\n",
    "sub = df.reset_index()\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
