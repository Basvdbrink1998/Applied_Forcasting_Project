{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_calendar = pd.read_csv(\"calendar_afcs2021.csv\", index_col=0)\n",
    "date_converter = dict(zip(store_calendar['d'], store_calendar.index))\n",
    "\n",
    "sell_prices = pd.read_csv(\"sell_prices_afcs2021.csv\", index_col=0)\n",
    "\n",
    "sample_submission = pd.read_csv(\"sample_submission_afcs2021.csv\", index_col=0)\n",
    "\n",
    "train_data = pd.read_csv(\"sales_train_validation_afcs2021.csv\", index_col=0)\n",
    "test_data = pd.read_csv(\"sales_test_validation_afcs2021.csv\", index_col=0)\n",
    "train_data = train_data.rename(columns=date_converter)\n",
    "test_data = test_data.rename(columns=date_converter)\n",
    "\n",
    "total_sales = train_data.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = train_data.transpose().describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc.loc['max'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some days where the total sales are almost zero, and one very high peak. Lets explore that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_low_days = total_sales[total_sales < 100].index\n",
    "print(very_low_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, so the store seems to be closed on chistmas day (25th of december)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_high_day = total_sales[total_sales > 3000].index\n",
    "print(very_high_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_calendar[store_calendar.index == very_high_day[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, it wasnt a really special day it seems. Maybe there was a massive sale or something like that? We'll look at that some other time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are some special days in the year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split the data set by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_total_sales = pd.DataFrame({'values': total_sales.values}, index=pd.DatetimeIndex(total_sales.index))\n",
    "ts_total_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales_by_year = dict()\n",
    "for year in range(2011, 2016):\n",
    "    total_sales_by_year[year] = ts_total_sales[ts_total_sales.index.year == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales_by_year[2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_by_month(df):\n",
    "    total_sales_by_month = dict()\n",
    "    for month in range(1, 13):\n",
    "        total_sales_by_month[month] = df[df.index.month == month]\n",
    "    return total_sales_by_month\n",
    "\n",
    "def get_highest_month(sales_by_month):\n",
    "    return calendar.month_abbr[np.array([sum(sales_by_month[month].values) for month in sales_by_month.keys()]).argmax() + 1]\n",
    "\n",
    "def get_lowest_month(sales_by_month):\n",
    "    return calendar.month_abbr[np.array([sum(sales_by_month[month].values) for month in sales_by_month.keys()]).argmin() + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in total_sales_by_year.keys():\n",
    "    sales = total_sales_by_month = get_sales_by_month(total_sales_by_year[year])\n",
    "    hm = get_highest_month(total_sales_by_month)\n",
    "    lm = get_lowest_month(total_sales_by_month)\n",
    "    print(\"In the year \" + str(year) + \", the highest sale month was: \" + hm + \". and the lowest was: \" + lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt at forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train_data = train_data.transpose()\n",
    "ts_train_data.index = pd.to_datetime(ts_train_data.index)\n",
    "ts_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = list(ts_train_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_forecast(data, product_names):\n",
    "    submission = []\n",
    "    \n",
    "    for i in product_names:\n",
    "        df = data[i]\n",
    "        model = ExponentialSmoothing(df ,seasonal_periods=7 ,trend='add', seasonal='add') \n",
    "        fitted = model.fit() \n",
    "        fc = fitted.forecast(28).tolist()\n",
    "        fc.insert(0, i)\n",
    "        submission.append(fc)\n",
    "\n",
    "    return pd.DataFrame(submission, columns=['id','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17','F18','F19','F20','F21','F22','F23','F24','F25','F26','F27','F28'])\n",
    "        \n",
    "df = make_submission(ts_train_data, products)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
